# graduation-project


■ 요약 
소비자와 기업 모두가 소비/생산에 대한 결정을 할 때 중요한 factor로 사용되는 것이 소비자의 리뷰이다. 이러한 리뷰의 데이터가 많아지는 만큼 무의미하고 광고성 리뷰 역시 많아지는 추세이며 이에 따라 소비자와 기업 모두 변별력 있고 신뢰할 수 있는 리뷰를 확보하는 것이 중요해졌다. 

본 프로젝트는 리뷰들을 Deep learning 기반의 모델에 학습시키고, 이 모델을 이용하여 리뷰들의 정보량과 신뢰성에 대해 5단계로 나누어진 평점을 부여하도록 한다. 이 평점을 통하여 더 신뢰할 만한 리뷰들만 뽑아내어, 생산자와 소비자 모두가 리뷰기반의 결정 시 도움을 받을 수 있도록 한다.        
■ 서론 
1. 과제의 필요성
<리뷰의 중요성과 의미가 없는 리뷰>
 2020년 1월 통계청이 발표한 자료에 따르면, 온라인쇼핑 거래 금액은 12조 3,906억원으로 전년동월대비 15.6%증가하였다. 또한 2020년 기준 소매판매액 중 온라인 쇼핑 거래액이 차지하는 비중은 23.2%에 달한다.
 
이와 같이 최근 온라인 시장이 확대됨에 따라 상품을 직접 확인하고, 선별하는 과정을 거치지 않고 상품을 구매하는 경우가 많다. 이에 따라, 상품에 대한 정보를 얻기 위해 상품을 먼저 구매한 다른 구매자들의 리뷰를 보고 상품에 대한 정보를 얻는 경우가 많아지고 있다. 이에 따라 더 많은 리뷰를 확보하기 위해서 포인트, 적립금을 지급해주는 등의 방식으로 구매자들이 리뷰를 남길 수 있도록 독려하고 있다.  예를 들어, 마이리얼트립은 후기를 작성한 고객에게 쿠폰을 제공하는 등 리뷰를 독려하는 이벤트로 홍보를 대체하고 있다. 그 결과 마이리얼트립에 올라온 누적 여행 후기 수는 2019 3월 기준 47만여 건에 달한다. 하지만 리뷰가 증가함에 따라서 그에 따라 상품광고, 적립금의 받기 위한 리뷰 등 의미가 없는 리뷰도 또한  증가하고 있다. 이러한 의미가 없는 리뷰들은 다음과 같은 다양한 문제를 발생시키고 있다. 

<의미 없는 리뷰의 문제점>
첫 번째로, 객관적인 리뷰를 선별하고 그를 통해서 정보를 얻는 데 까지 오랜 시간이 걸리게 된다. 제품을 구매하는 데 있어서 구매자가 상품들을 리뷰를 읽어보고 그것이 의미가 있는 리뷰인지를 판별하고, 그것을 기반으로 상품 구매를 고려한다. 이 때, 의미가 없는 리뷰가 많으면 그것이 의미가 있는 리뷰인지, 없는 리뷰인지를 판단하는 데에도 시간이 소모되게 된다. 이로 인해, 쓸데 없는 시간 낭비가 발생하게 된다. 

두 번째로, 상품의 점수에 인한 리뷰의 정확성 혼동이 발생한다. 대부분의 의미가 없는 리뷰들은 상품의 평점이 1-5점으로 주어질 때 5점으로 주어지는 경우가 허다하다. 이로 인해서 상품의 평점이 정상보다 높아지게 된다. 이는 리뷰의 정확성에 구매자들이 의문을 품을 가능성을 주게 된다. DMN의 조사에 따르면, 상품의 리뷰가 4.7에서 5점사이에 존재한다면 구매자들은 이 제품에 대한 리뷰가 신뢰성이 없다고 판단한다고 한다.  

 세 번째로, 상품의 광고로써 사용되는 리뷰로 인한 혼동이 발생한다. 최근 많은 기업에서 자신들이 판매하는 상품에 대해서 긍정적인 리뷰를 작성해주는 일명 리뷰 아르바이트를 많이 활용하고 있다. 그 결과, 특정 상품에 대해서 객관적이지 못한 긍정적인 리뷰들이 많이 작성이 되고 있다. 구매자들은 이러한 리뷰가 광고인지 일반 구매자가 작성한 리뷰인지를 구별할 뚜렷한 방법이 없다. 그로 인해서, 상품을 구매하는데 있어서, 상품을 구매하는 과정에서 객관적이지 않는 판단을 발생시킬 가능성이 농후하다.

 네 번째로, 기업이 리뷰를 분석 및 활용할 때  혼동을 초래할 수 있다. 많은 기업들이 상품에 대한 리뷰를 통해서 소비자들의 패턴을 분석하고 이를 활용하고 있다. 이때 의미가 없는 리뷰가 데이터로 존재 한다면 리뷰를 분석의 정확성을 낮추게 된다. 

<과제의 필요성>
 우리는 위에서 언급한 문제들을 해결하기 위해서 리뷰를 분석하여서 그 리뷰가 의미가 있는 리뷰인지 없는 리뷰인지를 판단하고자 한다. 이러한 작업의 필요성은 다음과 같다. 

 첫 번째로, 구매자가 의미가 있는 리뷰와 의미가 없는 리뷰를 분류하는데 낭비되는 시간을 아낄 수 있다. 많은 업무량으로 인해서 바쁜 하루를 보내는 현대인들에게 조금이나마 더 현명한 시간 소비를 할 수 있도록 도움을 줄 수 있다. 

 두 번째로, 리뷰에 대한 신뢰성을 증가시킬 수 있다. 위에서 언급하였듯이 4.7-5점사이의 높은 평점인 상품들은 객관적이지 못하다고 판단할 수 있다. 이로 인해서 정말 좋은 상품에 대한 의구심이 생길 수가 있다. 하지만 의미 없는 리뷰들을 제거하게 된다면 상품에 대한 구매자들의 신뢰성을 확보 할 수 있다. 

 세 번째로, 광고로써 사용되는 리뷰들을 제거함으로써 더 객관적인 소비를 할 수 있다. 상품을 구매하는데 있어서 기업에서 구매자가 더 많은 소비를 할 수 있도록 작성하는 의미가 없는 리뷰들을 제거 함으로써 실제 구매자들의 구매 후기를 통해서 상품을 구매하는 데 있어서 더 현명한 결정을 할 수 있게 된다.

 네 번째로, 기업이 리뷰를 분석하고 활용하는데 도움을 줄 수 있다. 기업이 리뷰를 분석할 때 의미가 없는 리뷰가 분석을 잘 못 된 방향으로 이루어지는 것을 방지 할 수 있기 때문에 기업은 이러한 리뷰를 활용해서 마케팅, 상품 추천 등에 이용함으로써 기업의 이익을 더욱 증가 시킬 수 있다. 


■ 관련연구 
<기술 현황>
몇 년 전으로부터 온라인상에서 홍보 목적으로 작성된 허위 리뷰를 기계적인 알고리즘으로 찾아내려는 연구가 발표되고 있다. 

<개별 리뷰의 특징을 분석하여 스팸을 탐지>
먼저 2008년 WSDB(Web Search and Data Mining) 컨퍼런스에 발표된 “Opinion Spam and Analysis” 라는 논문 에서는 리뷰를 문서 단위로 보면서 스팸 여부를 판단하고 있다. 스팸이라 함은, 특정 상품을 홍보, 혹은 깎아 내릴 목적으로 작성된 허위 리뷰 혹은 의견 스팸을 가리킨다.

이 연구에서 한 가정은 중복된 내용이 여기저기 많이 나온 리뷰를 스팸으로 가정했다. 이는 제품을 칭찬하는 글을 하나 잘 써놓고 이 제품 저 제품 리뷰에 재활용 하는 경우를 이용하였는데, 이러한 리뷰를 골라내기 위해 이용한 특성들은 다음과 같다.
•리뷰 길이
•리뷰에 대한 사람들의 평가
•리뷰가 작성된 순서
•긍정적/부정적 단어의 비율
•리뷰 내용과 제품 소개 내용과의 유사도
•리뷰 평점과 다른 사람들의 평점과의 일치도
•리뷰어가 쓴 리뷰 중에서 제품의 첫 리뷰였던 비율
(광고 목적의 리뷰는 첫 리뷰로 올리는 것이 효과적임을 이용)

<문서 작성자 단위로 파악>
2년 후 CIKM(Conference on Information and Knowledge Management)에 발표된 “평가 행위를 이용한 제품 리뷰 스패머 탐지(Detecting Product Review Spammers using Rating Behaviors)에서는 사용자 단위로 스패머를 찾으려는 시도를 하였다. 이는 작성자의 행위로부터 스팸 증거를 찾는 접근을 하였다. 사용자 단위로 분석한 특징은 다음과 같다.
•동일한 제품에 비슷한 내용과 평점의 리뷰를 여러 번 올리는 행위를 찾아낸다.
•그 사람이 올린 평점이 다른 사람과 얼마나 비슷했는지 살핀다.
•다른 리뷰가 없을 때 재빨리 리뷰를 올려 사람들의 판단에 영향을 주려고 하는 정도를 살핀다.

이러한 특성들을 점수화 하였고, 스팸 판정 방법에도 직접 학생들을 리쿠르팅 하여 스패머 여부를 판정하기도 하였다.

<리뷰의 내용을 보고 스팸여부 판단>
앞선 두 연구는 리뷰와 관련된 외부 요소에 의지하는 바가 컸다. 2011년 ACL(Association for Computational Linguistics)에 코넬대 연구진이 발표한 논문 “상상력 발휘 여부를 이용해서 기만적인 의견 스팸 찾기(Finding Deceptive Opinion Spam by Any Stretch of the Imagination)을 보면, 내용만을 보고 그게 가짜인지 허위인지를 판단하겠다는 것이다.

호텔에 실제 투숙한 양 위장하여 쓴 가짜리뷰와 정말 투숙하 여 쓴 진짜 리뷰 두 그룹을 식별하기 위해 머신러닝 알고리즘을 실험하였는데, 진짜 리뷰에는 명사/형용사/전치사/한정사(the, my)/등위접속사(and,but)가 상대적으로 많고, 가짜리뷰에는 동사/부사/대명사/전치한정사가 많았다고 한다. 특히 최상급 표현이 가짜 리뷰에 더 많은데, 이는 홍보가 목적인 만큼 과장된 표현이 많아 짐에 따른 결과이다. 또한 주요하게 쓰인 단어에서도 차이가 드러났는데, 진짜 리뷰에는 감각을 전달하는 단어가 빈번하고, 특히 장소와 관련되어 구체적인 표현이 많았다. Ex)small, bathroom, on, location 

<미국 Yelp 사이트의 가짜 리뷰 필터>
사실 허위 리뷰 필터링 기준, 노하우는 외부에 잘 공개하지 않는다. 그 이유는 그 필터의 기준을 공개 했을 때 필터링에 대한 어뷰징(abusing)에 대한 우려가 크기 때문이다. 

미국의 Yelp 사이트는 내부적으로 허위라고 판단한 리뷰들을 표시해놓고 있는데, 외부 연구자들은 이 “Yelp의 가짜 리뷰 필터는 어떻게 동작할까? (What Yelp Fake Review Filter Might Be Doing)” 라는 논문에서 이 사이트의 필터의 동작방식을 추측하고 있다.

이 논문에서 Yelp가 판단한 정상군과 스팸군의 차이를 분석했다. Yelp가 판단한 스팸군들은 실제 정상군의 리뷰보다 정교하지 못하다는 점. 등장하는 단어의 패턴이나 쓰임새가 아무래도 실제 리뷰와 차이가 나고, 잘 써야 한다는 동기부여가 약하기 때문이다. 또한 전체적인 단어 사용은 일반 리뷰와 비슷하지만, 특정한 어휘군들의 빈도는 특히 더 높더라 하는 것이 저자들의 발견이다.

또한 저자들은 내용 기반의 필터링 뿐만 아니라 Yelp 데이터에서 각각 사용자가 1) 얼마나 몰아서 한꺼번에 리뷰를 쓰는지, 2) 5점만점에 4점 이상을 준 비율이 얼마나 되는지, 3)쓴 리뷰의 길이가 얼마인지, 4)다른 사람의 평가와 얼마나 유사하고 다른지, 5) 작성한 리뷰들이 얼마나 비슷한지 등을 이용한 판별기를 만들어 정확도에서 내용 기반 분류기를 압도했다고 한다.

■ 제안 작품 소개 (4페이지 내외)
<작품의 구성>
1. 리뷰 크롤링
- 과제를 진행하는 과정에서 필요한 리뷰 데이터 셋을 웹에서 웹 크롤링을 사용하여서 확보
- Python의 BeautifulSoup 모듈을 활용하여서 정규표현식을 사용해서 html, xml등의 데이터에서 리뷰를 추출

2. 필터링 기준 선정 및 분류
- 필터링 기준 선정 및 선정 기준의 신뢰성 판단
- 판단된 신뢰성에 따라 리뷰의 의미 신뢰도를 분류

3. 분류된 결과를 토대로 한 딥러닝 학습
- Python의 Tensorflow, keras를 이욯하여 딥러닝 모델을 만들고 학습을 진행 

4. 테스트 및 검증
- 실제 리뷰에 적용하여서 리뷰의 신뢰성을 판단
- 적절한 신뢰성을 가지는 도출해 내는지에 대해 검증
<구매자의 기대효과>
상품을 구매할 때 의미없이 작성된 리뷰가 제외되기 때문에 리뷰의 신뢰성이 증가할 것이다. 또한 상품 홍보로 인한 리뷰가 제외되기 때문에 리뷰의 객관성이 증가할 것이다. 이로 인해 구매자가 상품을 구매할 때 각 리뷰에 대한 신뢰성을 확보할 수 있을 것이다. 또한 상품을 구매하는 과정에서 발생하는 리뷰를 선별하는 과정을 거치지 않기 때문에 상품을 구매하는 시간이 단축될 것이다. 그리고 평점 4.7-5사이의 높은 평점을 받은 상품에 대한 구매자의 신뢰성을 회복할 것이다. 

<기업의 기대효과>
기업의 입장에서 상품의 리뷰에 대한 분석을 용이하게 진행할 수 있다. 이로 인해 리뷰를 활용한 마케팅, 홍보 등에 도움이 될 것이다. 이에 따라 구매자들이 이것을 토대로 현명한 소비를 할 수 있도록 촉진할 수 있다. 또한 리뷰를 작성하도록 촉진하는 적립급, 포인트 제도가 잘 못 악용되는 사례를 방지할 수 있을 것이다. 

<개발자의 기대효과>
  데이터 셋을 분석하는 과정에서 의미가 없는 리뷰가 제거되기 때문에 개발 및 데이터 분석을 하는데 있어서 더욱 의미가 있는 결과를 도출할 수 있다. 이로 인해 리뷰를 활용한 개발이 더욱 활발하게 진행 될 것이다. 또한 이러한 분석 접근 방법을 리뷰 뿐만이 아니라 인터넷 커뮤니티의 댓글이나 실시간 트윗 등에도 적용할 수 있을 것이다.

■ 구현 및 결과분석 (4페이지 내외)
<구현>

1. 리뷰 크롤링
먼저 어떤 리뷰를 데이터셋으로 활용할지 고민하였다. 
긍정/부정이 크게 갈리며, 그 리뷰가 소비자의 결정에 큰 영향을 미치고, 각종 리뷰이벤트로 신뢰성이 떨어지는 리뷰들이 많거나 리뷰 조작 업체를 통한 가짜 리뷰 사례가 많은 음식 배달 플랫폼의 리뷰를 타겟팅하기로 했다. 대상 플랫폼은 웹 형태로도 서비스를 제공하는 ‘요기요‘를 선정하였다.

크롤링은 웹 브라우저를 컨트롤하여 웹 UI를 Automation 하는 도구인 Python의 Selenium 라이브러리를 사용하였다. 아래에 해당하는 과정을 자동화 하여 리뷰를 .csv 파일로 저장하였다.
위치설정 -> 카테고리별 검색 -> 해당 카테고리의 모든 음식점을 리스트에 추가 -> 리스트에 있는 모든 각 음식점의 세부페이지 이동 -> 모든 리뷰객체를 Pandas DataFrame에 저장

특히 음식의 카테고리별로 리뷰에 등장하는 단어의 특성이 다르기 때문에, 카테고리별로 따로 데이터셋을 저장하였다. 이번 중간보고에서는 특히 족발&보쌈 리뷰를 데이터셋으로 진행하기로 하였다.

2. 데이터 전처리
웹에서 크롤링 해온 데이터를 학습을 진행시키기 위해 데이터 전처리를 진행하였다. 먼저 pandas를 이용해 raw data를 읽어오는 과정으로 시작하였다. 이 때, 한글로 된 데이터이기 때문에 encoding을 utf-8로 설정을 해주었다. 

다음으로 학습을 진행하는데 필요 없는 문자들을 제거하는 과정을 진행하였다. 이모티콘이나 특수문자는 학습을 진행하는데 있어서 불필요하다고 판단하였다. 따라서 정규식을 이용하여서 불필요한 문자를 제거하였다. 

불필요한 문자를 제거한 후 계획한 방법대로 학습을 진행하기 위해 문장을 파싱하는 과정을 진행하였다. 이 때, konlpy라는 패키지 안에 있는 Hannanum을 사용하려고 하였으나 Hannanum은 문장을 형태소 기준으로 파싱하였을 때, 종류가 기준보다 적게 나와서 Kkma를 사용하여서 파싱을 진행하였다. 

문장을 파싱한 후 길이, 명사 종류의 수, 대명사, 접속사, 동사, 형용사, 리뷰관련 단어, 희귀단어를 기준으로 데이터 전처리를 진행하였다. 이 때, 명사 종류의 수, 대명사, 접속사, 동사, 형용사는 Kkma의 기능을 이용하여서 처리하였다. 다음으로 리뷰 관련 단어는 특정 문장에 리뷰, 사진이라는 단어가 나오게 된다면 리뷰 이벤트를 진행하기 위해 의미 없이 리뷰를 썼을 가능성이 높기 때문에 해당 단어가 나오는 횟수를 카운팅하였다. 마지막으로 희소한 단어를 사용하였을 때, 정성스럽게 리뷰를 작성하였을 가능성이 높기 때문에 희소한 단어를 찾는 과정을 진행하였다. 이를 위해 먼저 모든 문장에서 사용된 단어를 저장하고, 문장을 전처리하는 과정에서 저장된 리스트에 존재하는지 체크하는 방식을 통해 확인을 진행하였다. 

이렇게 처리된 데이터는 길이가 최소 0자에서 최대 400자 가까이 되기 때문에 학습을 제대로 진행되지 않을 가능성이 높다고 판단하였고, normalization과정을 진행해주었다. 이 때 min-max Normalizaion을 사용하였는데 분모의 값이 0이 되어 NAN값이 되는 것들은 학습을 진행할 수 없기 때문에 모두 0으로 처리하는 과정을 진행하였다.

3. Labeling
머신러닝 모델을 세워 학습을 시키기 위해서는 많은 양의 라벨링된 리뷰 데이터가 필요하다. 크롤러로 추출한 방대한 각 리뷰의 신뢰성, 그리고 정보량을 수치화하여 0~4 까지의 라벨링을 다는 작업이 필수적이었는데, 문제는 이를 자동화하는 것이 불가능 하였고, 또한 라벨링을 서로 다른사람이 수작업 하다보니 각자의 주관이 반영되어 일관 된 labeling 결과를 얻기 쉽지 않았다.

수작업을 하는데에 있어서 명확한 기준을 세워 최대한 일관된 데이터셋을 얻고자 하였다.

1점：굿, 맛있어요. 괜찮아요. 그냥저냥. 좋아요. 무성의한 리뷰 등 리뷰로부터 얻을 수 있는 정보량이 1개(맛/양/배달/메뉴/가성비 등의 정보 中 1) 혹은 그 이하일 경우에는 0점을 부여하였다.

2점 : 1점짜리 리뷰와 비교 했을 때 정보량이 하나 더 많다면, 1점을 부여하였다. 예를 들면, “맛있어요~ 잘먹었습니다” 가 1점 리뷰라면, “마늘족발이 맛있네요”, “배달이 빠르네요 맛도 좋아요” , “맛있는데 양이 좀 적네요” 는 2개의 정보량을 담고 있으므로 2점을 부여하였다. 
또한 정보량이 1개 이더라도, 희소성 있는 정보를 담는 경우에도 0점이 아닌 1점을 부여하였다. 가령 “봉다리 보온 센스가 좋네요” “고기가 머릿고기먹는 느낌입니다” 는 단순히 맛있다 라는 정보와는 빈도가 다른 희소한 정보이기에 더 높은 점수를 부여하였다.

3점 : 2점 리뷰와 비교 했을 때 정보량이 더 많아진 경우에 3점을 부여하였다. 기본적으로 앞선 1,2점 리뷰와 비교했을 때 리뷰의 길이 자체가 길어지고, 리뷰에 성의가 보이는 리뷰, 특히 그냥 맛있다는 정보보다 어떤 부분이 좋았는지 서술한 리뷰에는 3점을 부여하였다.

4점 : 3점 리뷰와 비교 했을 때 더 구체적인 리뷰를 작성한 경우에 4점을 부여하였다. 특히 풍부한 정보량과 더불어 푸석푸석, 따끈, 부족한 양념, 달달 등의 특히 맛에 대한 구체적 ‘묘사’ 가 많이 들어간 리뷰의 경우 4점을 부여하였다. 

5점 : 최고점인 경우로, 기본적으로 길이가 150자 이상으로 정보량이야 앞선 1~4점 보다 월등하며, 누가 봐도 정성이 느껴지며, 특히 리뷰에 좋았던 점과 아쉬웠던 점 모두를 담은 경우에는 최고점을 부여하였다. 
　
위 기준을 따라서 최대한 객관성을 부여하려고 노력하였고, 직접 수작업으로 족발&보쌈 리뷰에 대해서 라벨링 작업을 진행하였다. 

4. 모델 설계 및 학습
먼저, 학습을 진행하기 위해 만들어 놓은 데이터를 training : validation : test = 7 : 2: 1의 비율로 나누었다. 
Pytorch를 이용하여 학습을 진행하기 위해 데이터를 numpy로 변형하였고, 변형한 데이터를 loader에 올리는 과정을 진행하였다. 다음으로 MLP모델을 사용하기로 결정하였다. 3개의 층으로 구성하였고, 활성화 함수는 tanh를 사용하였다. 

첫번째 층은 input_dim = feature의 수 output_dim = 50, 두 번째층은 input_dim = 50, out_dim = 35, 세 번째층은 input_dim 35, output_dim=5로 진행을 하였다. 

이 후 learning rate는 0.001, epoch는 50, batch size는 128으로 설정하였다. 그리고 optimizer는 Adam을 이용하였다.

<결과 분석>
[표 3] training steps - loss 그래프 
 

위 그래프는 설계한 모델을 training set과 validation set에 적용한 결과이다. 그래프의 외형만 본다면 loss 가 줄어들며 모델이 잘 학습하고, training set과 validation set 모두 비슷한 그래프를 그리며 loss가 줄어들고 정확도가 올라가는 것으로 보인다. 

정말 잘 학습이 된 건지 의문이 드는 부분이 있다. 일단 몇 에폭 지나지 않아 금방 학습이 어느정도 잘 되어버리는 것이 첫 번째 의심되는 부분이고, test set으로 시험을 해본 결과 분포가 고르지 않고 2~3점 점수대에 지나치게 몰려있는 결과를 낸다는 것이 두 번째 의문점이다.
■ 결론 및 소감 (1페이지 내외)
현재까지 졸업작품을 진행하면서, 꾸준하게 회의를 진행하며 개발이 원활하게 진행될 수 있도록 소통하였다. 
이 과정을 통해 개발을 하기 전에 정했던 기준들을 가지고 어떻게 데이터를 처리할 것이며, 학습을 어떻게 진행할 것인지에 대해 구체적으로 상의하였다. 상의하는 과정에서 더 필요한 지식에 대해서 계속해서 공부를 진행하였고, 선행 사례에 대한 연구도 꾸준하게 진행하였다. 

그 후 개발을 시작하였지만, 예상과는 다른 결과가 나왔다. 처음 우리의 예상된 결과는 5개의 라벨에 대해 구체적으로 구별이 가능하리라고 생각을 하였다. 하지만 실제 결과에서는 5개의 라벨에 대한 결과값이 뚜렷하게 구분이 되지 않아서 정확하게 학습하고 결과가 도출되었다고 판단되기는 어렵다. 

따라서 라벨링에 대한 기준을 좀 더 학습이 잘 진행될 수 있도록 다른 방향으로 설정하고 라벨링 작업부터 다시 진행하려고 한다. 이에 대해 현재는 라벨링 작업을 5단계로 나눠서 진행하였지만, 3-4에 해당하는 라벨들이 뚜렷하게 구분 할 수 없다고 판단되었고, 이를 해결하기 위해 다른 기준으로 라벨링을 진행하려고 생각하고 있다. 
라벨링을 3개로 진행하는 것 또한 계획에 두고 있다. 또한 지금까지의 진행상황에서는 리뷰를 쪼개서 그것을 전처리하고 학습을 진행한 것이 구체적이지 못한 결과를 도출했다고 판단하였고, 다른 방식으로 개발을 진행하려고 한다. 

지금까지 조사한 결과에 따르면 text classification에 최적화 된 bert라는 모델을 염두에 두고 있다. Bert가 현재 우리가 개발하려는 작품을 학습하는데 적합한지에 대한 조사가 더 진행되어야 구체적으로 진행방향을 잡을 수 있을 것이라 판단하였고, 조사를 더 진행하기로 하였다. 또한 bert모델 뿐아니라 다른 효과적인 모델이 존재하는 지에 대해서도 계속해서 조사할 예정이다. 또한 지도교수님께 자문을 구하여 현재상황에 대한 설명을 드리고 도움을 요청할 계획을 가지고 있다.

■ 참고문헌 (1페이지 내외)
인용한 참고문헌입니다. 참고문헌 인용은 다음과 같이 합니다 [1].

[1]]통계청 http://kostat.go.kr/portal/korea/kor_nw/1/1/index.board?bmode=read&aSeq=380996

[2] DMN(Data Strategy Technology). https://www.dmnews.com/marketing-channels/social/article/13034979/5-online-review-factors-that-can-influence-conversion

[3] 김유림 저, “1등 브랜드는 이렇게 만드는 겁니다.” 

[4] 텐서플로우, https://www.tensorflow.org/?hl=ko

[5] 가짜 리뷰는 어떻게 골라낼까, http://slownews.kr/20009

[6] Nitin Jindal, Bing Liu, “Opinion spam and analysis”, February 2008

[7] Ee–Peng Lim, Viet-An Nguyen, Nitin Jindal , “Detecting product review spammers using rating behaviors” , October 2010

[8] Myle Ott, Yejin Choi, Claire Cardle , Jeffrey T. Hancock, “Finding Deceptive Opinion Spam by Any Stretch of the Imagination”, June 2011

[9] Arjun Mukherjee, Vivek Venkataraman, Bing Liu, Natalie Glance , “What Yelp Fake Review Filter Might Be Doing?”, 2013








